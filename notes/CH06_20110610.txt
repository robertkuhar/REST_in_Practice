Chapter 6:  Scaling Out

Doug will host us for the 2nd June meeting as well as the August meetings
http://www.flowplay.com/corp/index.shtml

GET Back to Basics
  Response includes headers which help consumers and any intermediaries on the network process the response.
  GET is "safe and idempotent".  Which makes it Cache Friendly.

Caching
  "Origin serers control the caching behavior of the representations they issue...using HTTP headers".
  "Freshness lifetime" period of time a cached copy is considered "fresh" and suitable as a response.
  "Caches will often add an Age response header to a cached response" /* THIS I did not know! */
  It appears the responsibility of the Cache to revalidate any stale representations.

Benefits of Caching
  1. Reduce bandwidth
  2. Reduce latency
  3. Reduce load on servers
  4. Hide network failures
       Caches provide fault tolerance by masking intermittent failures and delays from consumers.
       /* How does this deal the the stale representations? */

Caching and the Statelessness Constraint
  http://soundadvice.id.au/blog/2010/01/17/ by Benjamin Carlyle (fuzzyBSc)
    - "Uniform Interface" is a REST constraint as is "Stateless"
    - "...services in a REST-style architecture are stateless between requests.  They don't carry any session state on behalf of the clients that aren't currently in the process of making requests..."
    - "...any architecture that really scales will be one that seeks to make use of the resources available near the network edge (closest to the consumer)"
    - Stateless
      - Move as much storage space from services to the edge of the network as possible
      - REST sets the bar for statelessness at the request level:  No session state needs to be retained by the service between requests
      - The effect of this is that session state is moved back to the service consumer at the end of each request.  Any session state required to process subsequent request is included in those susbsequent requests.
      - He makes a distinction between "Session" and "Service" state
      - Cache exists in REST to counter the negative effects of stateless
    - Principal of Least Power
      - Provide your consumers with Information rather than a Program to run.  The consumers will figure out interesting ways to process the information.
    - Code on Demand
      - Service can push compute power requirements out to the edge of the network.
      - Javascript, Applets, HTML are examples of pushing the compute requirements out to the consumers.

I love the NOTE on Page 159:  "...polling is what allows the Web to scale..."

!! "By making respresentations cacheable, we get massive scale, but introduce latency between the resouce changing and those changes becoming visible to consumers"

Reasons for Not Caching
  1. GET requests with service dictated side effects (bandwidth cap on a particular client, for example)
  2. Zero-tolerance for discrepancy between representation and actual state of the resource.
     "This is particularly problematic when two or more overlapping resources manipulate the same underlying domain entity."
  3. If the Response contains sensative or personal data particular to a consumer
     "it is possible to cache responses in a way that requires the cache to authorize them with the origin server with every request"
  4. When the data changes so frequently that caching and revalidating a response adds more overhead than the origin server simply generating a fresh response with each request

Types of Caches {Local, Proxy, Reverse Proxy}
  Proxy servers are common intermediaries between consumers and origin servers
  
  Local
    stores representations from many origin servers on behalf of a single user agent, application, or machine.
    maybe held in memory
    maybe persisted to disk

  Proxy
    stores representations from many origin servers on behalf of many consumers.
    Hosted both inside and outside the corporate firewall
    
  Reverse Proxy (aka. Accelerator)
    stores representations from one origin server on behalf of many consumers
    located in front of an application or web server
    clusters improve redundancy and prevent popular resources from becoming server hotspots
    Squid, Varnish, Apache Traffic Server are examples

Making Content Cacheable
  "Responses to GET requests are cacheable by default"
    * The response should really have either an expiry time, or a validator
  POST can be made cacheable with an "Expires" header, or "Cache-Control".
  
Response Headers used for Caching
  2 main headers
    Expires
      specifies an absolute expiry time
      one year into the future indicates that the content never expires (seems strange)
      min is 0 (now) or a date that is now.

    Cache-Control
      used in both Requests and Responses
      controls the caching behavior of the response
      one or more comma-separated directives which determine if the response is cacheable, by who, and for how long
      http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9
      /* There are way more options here than I ever realized, I hope he explains them */


  "If we can determine an absolute expiry time, we should use an Expires header"  You can also or instead specify Cache-Control header with a max-age or s-maxage directive which specify a TTL (Time to Live)
    /* RFC2616 states that "...If a response includes both an Expires header and a max-age directive, the max-age directive overrides the Expires header, even if the Expires header is more restrictive." */

  Cacheable responses should include a Validator - either an ETag or LastModified header
    ETag
      In CH04 we talked about this for concurrency control it works for validating freshness equally well
    Last-Modified
      Date header specifies when the response was generated
      Last-Modified specifies when the resource last changed
      Last-Modified is only accurate down to the second.  For more fine-grained control, ETag is the only option

Using Caching Directives in Responses
  Cache-Control directives serve 3 functions
    1. Make a response cacheable
    2. Make a response uncacheable
    3. Specify the "freshness" of a cached response

    max-age=<delta-seconds>
       Controls both cacheability and freshness
       Local and Shared caches
       overrides any Expires header

    s-maxage=<delta-seconds>
       Controls both cacheability and freshness
       Shared caches ONLY 
       /* I thought this one was interesting */

    public 
      Local and Shared caches
      NO EFFECT ON FRESHNESS
      takes precedence over authorization headers, allowing the reponse to be cached in the presence of Auhorization header (which would typically suppress the cachinig)

    private
      Local caches ONLY
      NO EFFECT ON FRESHNESS

    must-revalidate
      Makes an uncacheable response cacheable, but requires cache to revalidate with origin server
      Efficient validation on the origin server side reduces bandwidth consumption via 304 Not Modified responses

    proxy-revalidate
      Shared caches ONLY
      similar to must-revalidate

    no-cache
      Requires cache to revalidate a cached response with the origin server with every request
      Implementations vary on its function

    no-store
      Makes normally cacheable content uncacheable by all caches

  HTTP Stale Controls RFC adds...

    stale-while-revalidate=<delta-seconds>
      Instructs the cache to immediately send a stale response, and revalidate in the background, until delta-seconds have passed, then it should stop serving it.
      Favors reduced latency over consistency

    stale-if-error=<delta-seconds>
      Allows a cache to release a stale response if it encounters an error while contacting the origin server.  
      If a response is staler than the stale window specified by delta-seconds, it should not be released.
      This directive favors avail- ability over consistency.

  Squid 2.7 implements these last two
